{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Detection using TFIDFVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant Libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>EmailText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          EmailText\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\hp\\\\Desktop\\\\spam_detection\\\\spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Label        5572 non-null object\n",
      "EmailText    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above info shows that there are no null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>EmailText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label               EmailText\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">EmailText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmailText                                                               \n",
       "          count unique                                                top freq\n",
       "Label                                                                         \n",
       "ham        4825   4516                             Sorry, I'll call later   30\n",
       "spam        747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df.Label).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa44a053c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa449c2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(df['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates.\n",
    "\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations and stop words.\n",
    "# Creating a function to perform the tasks.\n",
    "# The below function works in preprocessing text for both Count and Tfidf Vectorizers.\n",
    "\n",
    "def preprocess(text):\n",
    "    # Removing punctuations.\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenizing, and then Removing stopwords.\n",
    "    clean = [word for word in text.split() if word.lower() not in stopwords.words('english')] # If word is not in stopwords.words, release (print) it else, hold it back (delete).\n",
    "    \n",
    "    return \" \".join(clean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to the input feature (EmailText).\n",
    "\n",
    "df['cleaned_mssg'] = df['EmailText'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go jurong point crazy Available bugis n great ...\n",
       "1                              Ok lar Joking wif u oni\n",
       "2    Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3                  U dun say early hor U c already say\n",
       "4          Nah dont think goes usf lives around though\n",
       "Name: cleaned_mssg, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_mssg'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['cleaned_mssg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LabelBinarizer to encode the label\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label = LabelBinarizer()\n",
    "df['Label'] = label.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>EmailText</th>\n",
       "      <th>cleaned_mssg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                          EmailText  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...   \n",
       "1      0                      Ok lar... Joking wif u oni...   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "\n",
       "                                        cleaned_mssg  \n",
       "0  Go jurong point crazy Available bugis n great ...  \n",
       "1                            Ok lar Joking wif u oni  \n",
       "2  Free entry 2 wkly comp win FA Cup final tkts 2...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the output\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting texts to vectors.\n",
    "\n",
    "vectorize = TfidfVectorizer(ngram_range=(1, 2), max_df=0.7, min_df=2)\n",
    "features = vectorize.fit_transform(df['cleaned_mssg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5169x7439 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 49067 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y.\n",
    "\n",
    "x = features\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:  (5169, 7439)\n",
      "Shape of y:  (5169,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of x and y.\n",
    "\n",
    "print('Shape of x: ',x.shape)\n",
    "print('Shape of y: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (4135, 7439)\n",
      "y_train:  (4135,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of train set.\n",
    "\n",
    "print('x_train: ',x_train.shape)\n",
    "print('y_train: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test:  (1034, 7439)\n",
      "y_test:  (1034,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of test set.\n",
    "\n",
    "print('x_test: ',x_test.shape)\n",
    "print('y_test: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHM 1\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training/fitting the Logistic Regression model.\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the model.\n",
    "\n",
    "y_pred1 = lr.predict(x_test)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation.\n",
    "from sklearn import metrics\n",
    "\n",
    "# let's create a function for evaluation.\n",
    "def evaluate(test, pred):\n",
    "    accuracy = metrics.accuracy_score(test, pred)\n",
    "    con_mat = metrics.confusion_matrix(test, pred)\n",
    "    report = metrics.classification_report(test, pred)\n",
    "    \n",
    "    print('accuracy: {:.3f}'.format(accuracy))\n",
    "    print()\n",
    "    print('confusion matrix:\\n',con_mat)\n",
    "    print()\n",
    "    print('classification report:\\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.939\n",
      "\n",
      "confusion matrix:\n",
      " [[908   0]\n",
      " [ 63  63]]\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       908\n",
      "           1       1.00      0.50      0.67       126\n",
      "\n",
      "    accuracy                           0.94      1034\n",
      "   macro avg       0.97      0.75      0.82      1034\n",
      "weighted avg       0.94      0.94      0.93      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate.\n",
    "\n",
    "evaluate(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.939\n",
      "train accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "# Let's compare train and test accuracies.\n",
    "\n",
    "print('test accuracy: {:.3f}'.format(lr.score(x_test, y_test)))\n",
    "print('train accuracy: {:.3f}'.format(lr.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHM 2\n",
    "# NAIVE BAYES\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Naive Bayes model.\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making Prediction.\n",
    "\n",
    "y_pred2 = nb.predict(x_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.963\n",
      "\n",
      "confusion matrix:\n",
      " [[908   0]\n",
      " [ 38  88]]\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       908\n",
      "           1       1.00      0.70      0.82       126\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.98      0.85      0.90      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Model's Performance.\n",
    "\n",
    "evaluate(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENT: Explain precision, recall, f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.963\n",
      "train accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "# Let's compare train and test accuracies.\n",
    "\n",
    "print('test accuracy: {:.3f}'.format(nb.score(x_test, y_test)))\n",
    "print('train accuracy: {:.3f}'.format(nb.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHM 3\n",
    "# Support Vector Classifier\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the SVC model.\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict.\n",
    "\n",
    "y_pred3 = svc.predict(x_test)\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.878\n",
      "\n",
      "confusion matrix:\n",
      " [[908   0]\n",
      " [126   0]]\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       908\n",
      "           1       0.00      0.00      0.00       126\n",
      "\n",
      "    accuracy                           0.88      1034\n",
      "   macro avg       0.44      0.50      0.47      1034\n",
      "weighted avg       0.77      0.88      0.82      1034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate.\n",
    "\n",
    "evaluate(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.878\n",
      "train accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Let's compare train and test accuracies.\n",
    "\n",
    "print('test accuracy: {:.3f}'.format(svc.score(x_test, y_test)))\n",
    "print('train accuracy: {:.3f}'.format(svc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS VALIDATING OUR MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95945946, 0.95173745, 0.93436293, 0.94390716, 0.94970986,\n",
       "       0.94777563, 0.93604651, 0.9496124 , 0.95155039, 0.95155039])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To ensure that every data in the data set is involved in training and validation.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Validation score for our Logistic Regression model.\n",
    "\n",
    "lr_score = cross_val_score(lr, x, y, cv=10, scoring='accuracy')\n",
    "lr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97876448, 0.97683398, 0.96332046, 0.96711799, 0.9729207 ,\n",
       "       0.96711799, 0.97093023, 0.97286822, 0.97093023, 0.97286822])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation score for our Naive Bayes model.\n",
    "\n",
    "nb_score = cross_val_score(nb, x, y, cv=10, scoring='accuracy')\n",
    "nb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95945946, 0.95173745, 0.93436293, 0.94390716, 0.94970986,\n",
       "       0.94777563, 0.93604651, 0.9496124 , 0.95155039, 0.95155039])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation score for our SVC model.\n",
    "\n",
    "svc_score = cross_val_score(lr, x, y, cv=10, scoring='accuracy')\n",
    "svc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.948\n",
      "Naive Bayes: 0.971\n",
      "SVC: 0.948\n"
     ]
    }
   ],
   "source": [
    "# Which of these three models has the highest average validation score?\n",
    "\n",
    "print('Logistic Regression: {:.3f}'.format(lr_score.mean()))\n",
    "print('Naive Bayes: {:.3f}'.format(nb_score.mean()))\n",
    "print('SVC: {:.3f}'.format(svc_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will therefore use Naive Bayes as our Email Spam Classification Model.\n",
    "# It has little parameters for tuning and will likely not require GridSearchCv for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FURTHER OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will apply a Token Normalization technique known as STEMMING to see if it will improve the model.\n",
    "# We can also try normalizing the length of the words / Lemmatizing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
